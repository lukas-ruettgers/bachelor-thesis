%% Main bibliography file
%%
%% REFER TO biblatex documentation for details about possible fields
%% bibtex support depends on the bibtex style (.bst) and is usually more limited

@article{godel1931formal,
  title={{\"U}ber formal unentscheidbare S{\"a}tze der Principia Mathematica und verwandter Systeme {I}},
  author={G{\"o}del, Kurt},
  journal={Monatshefte f{\"u}r Mathematik und Physik},
  volume={38},
  pages={173--198},
  year={1931},
  publisher={Springer}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@inproceedings{tishby2015deep,
  title={Deep learning and the information bottleneck principle},
  author={Tishby, Naftali and Zaslavsky, Noga},
  booktitle={2015 ieee information theory workshop (itw)},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@inproceedings{krueger2021out,
  title={Out-of-distribution generalization via risk extrapolation (rex)},
  author={Krueger, David and Caballero, Ethan and Jacobsen, Joern-Henrik and Zhang, Amy and Binas, Jonathan and Zhang, Dinghuai and Le Priol, Remi and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5815--5826},
  year={2021},
  organization={PMLR}
}

@article{pfister2019invariant,
  title={Invariant causal prediction for sequential data},
  author={Pfister, Niklas and B{\"u}hlmann, Peter and Peters, Jonas},
  journal={Journal of the American Statistical Association},
  volume={114},
  number={527},
  pages={1264--1276},
  year={2019},
  publisher={Taylor \& Francis}
}

@book{grunwald2007minimum,
  title={The minimum description length principle},
  author={Gr{\"u}nwald, Peter D},
  year={2007},
  publisher={MIT press}
}

@article{grunwald2019minimum,
  title={Minimum description length revisited},
  author={Gr{\"u}nwald, Peter and Roos, Teemu},
  journal={International journal of mathematics for industry},
  volume={11},
  number={01},
  pages={1930001},
  year={2019},
  publisher={World Scientific}
}

@article{richens2024robust,
  title={Robust agents learn causal world models},
  author={Richens, Jonathan and Everitt, Tom},
  journal={arXiv preprint arXiv:2402.10877},
  year={2024}
}

@article{solomonoff1964formal,
  title={A formal theory of inductive inference. {Part I}},
  author={Solomonoff, Ray J},
  journal={Information and control},
  volume={7},
  number={1},
  pages={1--22},
  year={1964},
  publisher={Elsevier}
}

@article{peters2016causal,
  title={Causal inference by using invariant prediction: identification and confidence intervals},
  author={Peters, Jonas and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={78},
  number={5},
  pages={947--1012},
  year={2016},
  publisher={Oxford University Press}
}

@article{ahuja2021invariance,
  title={Invariance principle meets information bottleneck for out-of-distribution generalization},
  author={Ahuja, Kartik and Caballero, Ethan and Zhang, Dinghuai and Gagnon-Audet, Jean-Christophe and Bengio, Yoshua and Mitliagkas, Ioannis and Rish, Irina},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3438--3450},
  year={2021}
}

@article{xu2019can,
  title={What can neural networks reason about?},
  author={Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1905.13211},
  year={2019}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@article{legg2007universal,
  title={Universal intelligence: A definition of machine intelligence},
  author={Legg, Shane and Hutter, Marcus},
  journal={Minds and machines},
  volume={17},
  pages={391--444},
  year={2007},
  publisher={Springer}
}

@book{li2008kolmogorov,
  title={An introduction to Kolmogorov complexity and its applications},
  author={Li, Ming and Vit{\'a}nyi, Paul and others},
  volume={3},
  year={2008},
  publisher={Springer}
}

@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{lake2017building,
  title={Building machines that learn and think like people},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and brain sciences},
  volume={40},
  pages={e253},
  year={2017},
  publisher={Cambridge University Press}
}

@article{solomonoff1978complexity,
  title={Complexity-based induction systems: comparisons and convergence theorems},
  author={Solomonoff, Ray},
  journal={IEEE transactions on Information Theory},
  volume={24},
  number={4},
  pages={422--432},
  year={1978},
  publisher={IEEE}
}

@article{levin1973universal,
  title={Universal sequential search problems},
  author={Levin, Leonid Anatolevich},
  journal={Problemy peredachi informatsii},
  volume={9},
  number={3},
  pages={115--116},
  year={1973},
  publisher={Russian Academy of Sciences, Branch of Informatics, Computer Equipment and~…}
}

@InProceedings{10.1007/3-540-58907-4_9,
author="Tyszkiewicz, Jerzy",
editor="Gottlob, Georg and Vardi, Moshe Y.",
title="On the Kolmogorov expressive power of boolean query languages",
booktitle="Database Theory --- ICDT '95",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="97--110",
abstract="We develop a Kolmogorov complexity based tool to measure expressive power of query languages over finite structures. It works for sentences (i.e., boolean queries), and gives a meaningful definition of the expressive power of a query language in a single finite model.",
isbn="978-3-540-49136-1"
}

@article{vapnik1991principles,
  title={Principles of risk minimization for learning theory},
  author={Vapnik, Vladimir},
  journal={Advances in neural information processing systems},
  volume={4},
  year={1991}
}

@article{turing1937computability,
  title={Computability and $\lambda$-definability},
  author={Turing, Alan M},
  journal={The Journal of Symbolic Logic},
  volume={2},
  number={4},
  pages={153--163},
  year={1937},
  publisher={Cambridge University Press}
}

@article{turing2004intelligent,
  title={Intelligent machinery (1948)},
  author={Turing, Alan Mathison},
  journal={B. Jack Copeland},
  pages={395},
  year={2004}
}

@article{turing1936computable,
  title={On computable numbers, with an application to the Entscheidungsproblem},
  author={Turing, Alan Mathison and others},
  journal={J. of Math},
  volume={58},
  number={345-363},
  pages={5},
  year={1936}
}

@book{rosenblatt1962principles,
  title={Principles of neurodynamics: Perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank and others},
  volume={55},
  year={1962},
  publisher={Spartan books Washington, DC}
}

@article{LESHNO1993861,
title = {Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
journal = {Neural Networks},
volume = {6},
number = {6},
pages = {861-867},
year = {1993},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(05)80131-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608005801315},
author = {Moshe Leshno and Vladimir Ya. Lin and Allan Pinkus and Shimon Schocken},
keywords = {Multilayer feedforward networks, Activation functions, Role of threshold, Universal approximation capabilities, (μ) approximation},
abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold.}
}

@inproceedings{haley1992extrapolation,
  title={Extrapolation limitations of multilayer feedforward neural networks},
  author={Haley, Pamela J and Soloway, DONALD},
  booktitle={[Proceedings 1992] IJCNN international joint conference on neural networks},
  volume={4},
  pages={25--30},
  year={1992},
  organization={IEEE}
}

@article{chaitin1974information,
  title={Information-theoretic limitations of formal systems},
  author={Chaitin, Gregory J},
  journal={Journal of the ACM (JACM)},
  volume={21},
  number={3},
  pages={403--424},
  year={1974},
  publisher={ACM New York, NY, USA}
}

@article{cilibrasi2005clustering,
  title={Clustering by compression},
  author={Cilibrasi, Rudi and Vit{\'a}nyi, Paul MB},
  journal={IEEE Transactions on Information theory},
  volume={51},
  number={4},
  pages={1523--1545},
  year={2005},
  publisher={IEEE}
}

@article{campi2023compression,
  title={Compression, generalization and learning},
  author={Campi, Marco C and Garatti, Simone},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={339},
  pages={1--74},
  year={2023}
}

@article{paccagnan2024pick,
  title={The Pick-to-Learn algorithm: Empowering compression for tight generalization bounds and improved post-training performance},
  author={Paccagnan, Dario and Campi, Marco and Garatti, Simone},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{vitanyi2020incomputable,
	title={How incomputable is Kolmogorov complexity?},
	author={Vit{\'a}nyi, Paul MB},
	journal={Entropy},
	volume={22},
	number={4},
	pages={408},
	year={2020},
	publisher={MDPI}
}
@article{welch1984technique,
	title={A technique for high-performance data compression},
	author={Welch, Terry A.},
	journal={Computer},
	volume={17},
	number={06},
	pages={8--19},
	year={1984},
	publisher={IEEE Computer Society}
}

@article{alakuijala2018brotli,
	title={Brotli: A general-purpose data compressor},
	author={Alakuijala, Jyrki and Farruggia, Andrea and Ferragina, Paolo and Kliuchnikov, Eugene and Obryk, Robert and Szabadka, Zoltan and Vandevenne, Lode},
	journal={ACM Transactions on Information Systems (TOIS)},
	volume={37},
	number={1},
	pages={1--30},
	year={2018},
	publisher={ACM New York, NY, USA}
}

@misc{deutsch1996rfc1951,
	title={Rfc1951: Deflate compressed data format specification version 1.3},
	author={Deutsch, Peter},
	year={1996},
	publisher={RFC Editor}
}

@article{alakuijala2015comparison,
	title={Comparison of brotli, deflate, zopfli, lzma, lzham and bzip2 compression algorithms},
	author={Alakuijala, Jyrki and Kliuchnikov, Evgenii and Szabadka, Zoltan and Vandevenne, Lode},
	journal={Google Inc},
	pages={1--6},
	year={2015}
}

@article{goldblum2023no,
	title={The no free lunch theorem, kolmogorov complexity, and the role of inductive biases in machine learning},
	author={Goldblum, Micah and Finzi, Marc and Rowan, Keefer and Wilson, Andrew Gordon},
	journal={arXiv preprint arXiv:2304.05366},
	year={2023}
}

@article{brown2020language,
	title={Language models are few-shot learners},
	author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={1877--1901},
	year={2020}
}

@book{shalev2014understanding,
	title={Understanding machine learning: From theory to algorithms},
	author={Shalev-Shwartz, Shai and Ben-David, Shai},
	year={2014},
	publisher={Cambridge university press}
}

@article{wang2022generalizing,
	title={Generalizing to unseen domains: A survey on domain generalization},
	author={Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Qin, Tao and Lu, Wang and Chen, Yiqiang and Zeng, Wenjun and Philip, S Yu},
	journal={IEEE transactions on knowledge and data engineering},
	volume={35},
	number={8},
	pages={8052--8072},
	year={2022},
	publisher={IEEE}
}

@inproceedings{kamath2021does,
	title={Does invariant risk minimization capture invariance?},
	author={Kamath, Pritish and Tangella, Akilesh and Sutherland, Danica and Srebro, Nathan},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={4069--4077},
	year={2021},
	organization={PMLR}
}

@article{rosenfeld2020risks,
	title={The risks of invariant risk minimization},
	author={Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
	journal={arXiv preprint arXiv:2010.05761},
	year={2020}
}
@article{scholkopf2021toward,
	title={Toward causal representation learning},
	author={Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
	journal={Proceedings of the IEEE},
	volume={109},
	number={5},
	pages={612--634},
	year={2021},
	publisher={IEEE}
}
@book{o2014analysis,
	title={Analysis of boolean functions},
	author={O'Donnell, Ryan},
	year={2014},
	publisher={Cambridge University Press}
}
